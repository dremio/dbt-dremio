name: CI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  run-tests:
    name: Setup and Run Tests
    runs-on: ubuntu-latest
    env:
      RETRY_COUNT: 12 # number of retries for health checks
      SLEEP_INTERVAL: 5 # Sleep duration in seconds between retries
      MINIO_HEALTH_URL: http://localhost:9000/minio/health/live
      DREMIO_HEALTH_URL: http://localhost:9047
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password
      DREMIO_SOFTWARE_USERNAME: dremio
      DREMIO_SOFTWARE_PASSWORD: dremio123
      DREMIO_SOFTWARE_HOST: localhost
      DREMIO_DATALAKE: dbt_test_source
      DREMIO_DATABASE: dbt_test
      DBT_TEST_USER_1: dbt_test_user_1
      DBT_TEST_USER_2: dbt_test_user_2
      DBT_TEST_USER_3: dbt_test_user_3

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Create Docker Network
        run: |
          docker network create ci-network || echo "Network already exists"

      - name: Start MinIO Service
        run: bash .github/scripts/start_minio.sh

      - name: Start Dremio Service
        run: bash .github/scripts/start_dremio.sh

      - name: Install MinIO Client (mc)
        run: bash .github/scripts/install_minio_client.sh

      - name: Create MinIO bucket
        run: bash .github/scripts/create_minio_bucket.sh

      - name: Create and Format Sources
        run: bash .github/scripts/create_and_format_sources.sh

      - name: Install Dependencies
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Python Dependencies
        run: |
          pip install --upgrade pip
          pip install -r dev_requirements.txt
          pip install .

      - name: Create dbt test users
        run: bash .github/scripts/create_dbt_test_users.sh

      - name: Create dbt projects
        run: bash .github/scripts/create_dbt_projects.sh

      - name: Clean up __pycache__ directories
        run: |
          find . -type d -name "__pycache__" -exec rm -r {} +

      - name: Create .env file for tests
        run: bash .github/scripts/create_env_file.sh

      - name: Discover Test Directories
        id: discover-tests
        run: |
          test_dirs=$(find tests/ -type f \( -name 'test_*.py' -o -name '*_test.py' \) -exec dirname {} \; | sort -u | jq -R -s -c 'split("\n") | map(select(length > 0))')
          echo "test_dirs=$test_dirs" >> $GITHUB_OUTPUT

  run-parallel-tests:
    name: Run Parallel Tests
    runs-on: ubuntu-latest
    needs: run-tests
    strategy:
      matrix:
        test_dir: ${{ fromJson(needs.run-tests.outputs.test_dirs) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set Up Python Environment
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Python Dependencies
        run: |
          pip install --upgrade pip
          pip install -r dev_requirements.txt
          pip install .

      - name: Run tests
        run: |
          mkdir -p reports
          report_file="reports/${{ matrix.test_dir }}.txt"
          pytest ${{ matrix.test_dir }} | tee $report_file

      - name: Upload test report
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.test_dir }}-report
          path: reports/${{ matrix.test_dir }}.txt

  upload-individual-test-reports:
    name: Upload Tests Artifacts
    runs-on: ubuntu-latest
    needs: run-parallel-tests
    steps:
      - name: Download test reports
        uses: actions/download-artifact@v4
        with:
          name: ${{ matrix.test_dir }}-report
          path: reports/
          
      - name: Upload individual test reports
        uses: actions/upload-artifact@v4
        with:
          name: individual-test-reports
          path: reports/*.txt

  verify-failures:
    name: Verify Expected Test Failures
    runs-on: ubuntu-latest
    needs: [run-parallel-tests, upload-individual-test-reports]
    steps:
      - name: Check out repository
        uses: actions/checkout@v3.5.2

      - name: Download All Test Reports
        uses: actions/download-artifact@v4
        with:
          name: all-tests-reports
          path: reports/

      - name: Set Up Python Environment
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Extract Actual Failed Tests
        run: |
          shopt -s globstar
          grep "FAILED tests" reports/**/*.txt | awk '{print $2}' | sort > actual_failures_sorted.txt

      - name: Sort Expected Failures
        run: sort .github/expected_failures.txt > expected_failures_sorted.txt

      - name: Compare Actual Failures with Expected Failures
        run: |
          echo "Expected Failures:"
          cat expected_failures_sorted.txt
          echo ""
          echo "Actual Failures:"
          cat actual_failures_sorted.txt
          echo ""

          # Identify unexpected failures
          unexpected_failures=$(comm -13 expected_failures_sorted.txt actual_failures_sorted.txt)

          # Identify missing expected failures
          missing_failures=$(comm -23 expected_failures_sorted.txt actual_failures_sorted.txt)

          # Initialize exit code
          exit_code=0

          if [ -n "$unexpected_failures" ]; then
            echo "Unexpected test failures detected:"
            echo "$unexpected_failures"
            exit_code=1
          fi

          if [ -n "$missing_failures" ]; then
            echo "Expected test failures that did not occur (they passed):"
            echo "$missing_failures"
            exit_code=1
          fi

          if [ $exit_code -eq 0 ]; then
            echo "All failed tests are expected, and all expected failures have occurred."
          else
            echo "Verification failed: There are unexpected or missing test failures."
          fi

          exit $exit_code